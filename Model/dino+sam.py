# -*- coding: utf-8 -*-
"""Dino+Sam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1skM8pWqxg6S-IdIntwm5wO-iM_Igz6HR
"""

!pip install -q groundingdino-py opencv-python Pillow
!pip install -q segment-anything
!pip install -q requests


!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth


import requests
config_url = "https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py"
config_filename = "GroundingDINO_SwinT_OGC.py"
print(f"Downloading {config_filename}...")
response = requests.get(config_url)
with open(config_filename, "w") as f:
    f.write(response.text)
print(f"Successfully downloaded {config_filename}.")



!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth


import cv2
import numpy as np
from PIL import Image
import torch
import torchvision.transforms as T
from groundingdino.util.inference import load_model, predict
from segment_anything import build_sam_vit_h, SamPredictor
from google.colab.patches import cv2_imshow # Used to display images in Colab
from google.colab import files # Used to upload files in Colab


def initialize_models():
    """Initializes and loads the Grounding DINO and SAM models."""
    print("Initializing Grounding DINO model...")

    dino_model = load_model("GroundingDINO_SwinT_OGC.py", "groundingdino_swint_ogc.pth")

    print("Initializing SAM model...")

    sam = build_sam_vit_h(checkpoint="sam_vit_h_4b8939.pth")
    sam_predictor = SamPredictor(sam)

    return dino_model, sam_predictor


def zero_shot_segmentation(image_path, text_prompt, dino_model, sam_predictor):
    """
    Performs zero-shot segmentation using Grounding DINO for bounding boxes
    and SAM for segmentation masks.
    """
    print(f"Loading image from {image_path}...")
    image_pil = Image.open(image_path).convert("RGB")
    image_cv = np.array(image_pil)


    transform = T.Compose([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image_tensor = transform(image_pil)

    # Set the image for the SAM predictor.
    sam_predictor.set_image(image_cv)

    print(f"Running Grounding DINO with prompt: '{text_prompt}'...")

    dino_boxes, _, _ = predict(
        model=dino_model,
        image=image_tensor,
        caption=text_prompt,
        box_threshold=0.3,
        text_threshold=0.25
    )

    if len(dino_boxes) == 0:
        print("Grounding DINO did not detect any objects for the given prompt.")
        return None


    h, w, _ = image_cv.shape


    dino_boxes_numpy = dino_boxes.cpu().numpy()
    dino_boxes_xyxy = dino_boxes_numpy * np.array([w, h, w, h])

    print(f"Grounding DINO detected {len(dino_boxes)} potential objects. Now using SAM for segmentation...")

    masks, _, _ = sam_predictor.predict(
        point_coords=None,
        point_labels=None,
        box=dino_boxes_xyxy,
        multimask_output=False
    )

    return masks


def visualize_results(image_path, masks):
    """
    Overlays the segmentation masks on the original image for visualization
    and displays the result in the Colab notebook.
    """
    image = cv2.imread(image_path)

    colors = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0]]

    if masks is not None:
        overlay = np.zeros_like(image, dtype=np.uint8)
        for i, mask in enumerate(masks):
            color = colors[i % len(colors)]
            overlay[mask] = color

        alpha = 0.5 # Transparency factor
        final_image = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)
    else:
        final_image = image

    print(f"Found {len(masks) if masks is not None else 0} objects.")
    print("Displaying the result...")

    cv2_imshow(final_image)



if __name__ == "__main__":

    print("Please upload an image for the audit.")
    uploaded = files.upload()
    image_filename = next(iter(uploaded))


    target_prompt = "a solar panel array"


    dino_model, sam_predictor = initialize_models()


    masks = zero_shot_segmentation(image_filename, target_prompt, dino_model, sam_predictor)


    visualize_results(image_filename, masks)

