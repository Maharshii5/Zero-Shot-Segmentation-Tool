# -*- coding: utf-8 -*-
"""prefinalworking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16chJgcGnFQ2_NtSPbiilg8u5FwGJw4lk
"""

!pip install -q groundingdino-py opencv-python Pillow
!pip install -q segment-anything
!pip install -q requests
from io import BytesIO


!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
!wget -q https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py
!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth


import cv2
import numpy as np
from PIL import Image
import torch
import torchvision.transforms as T
from groundingdino.util.inference import load_model, predict
from segment_anything import build_sam_vit_h, SamPredictor
from google.colab.patches import cv2_imshow
from google.colab import files
import sys



def check_gpu():
    """Checks if a GPU is available and exits if not."""
    if not torch.cuda.is_available():
        print("A GPU is required to run this model. Please enable it in Colab.")
        print("Go to Runtime -> Change runtime type -> GPU.")
        sys.exit(1)
    else:
        print("GPU detected. Continuing with model initialization.")

def initialize_models():
    """Initializes and loads the Grounding DINO and SAM models."""
    check_gpu()
    print("\n--- Initializing Models ---")
    print("Loading Grounding DINO model...")
    dino_model = load_model("GroundingDINO_SwinT_OGC.py", "groundingdino_swint_ogc.pth")
    print("Loading Segment Anything Model...")
    sam = build_sam_vit_h(checkpoint="sam_vit_h_4b8939.pth")
    sam_predictor = SamPredictor(sam)
    return dino_model, sam_predictor



def zero_shot_segmentation(image_path, text_prompt, dino_model, sam_predictor):
    """
    Performs zero-shot segmentation using the hybrid DINO-SAM pipeline.
    """
    print("\n--- Starting Segmentation Pipeline ---")
    print(f"Using image: {image_path}")
    print(f"Target prompt: '{text_prompt}'")

    image_pil = Image.open(image_path).convert("RGB")
    image_cv = np.array(image_pil)

    transform = T.Compose([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image_tensor = transform(image_pil)

    sam_predictor.set_image(image_cv)

    print("Step 1: Grounding DINO detecting objects...")
    dino_boxes, _, _ = predict(
        model=dino_model,
        image=image_tensor,
        caption=text_prompt,
        box_threshold=0.3,
        text_threshold=0.25
    )

    if len(dino_boxes) == 0:
        print("No objects detected. Try adjusting the prompt or thresholds.")
        return None, image_cv

    h, w, _ = image_cv.shape
    dino_boxes_numpy = dino_boxes.cpu().numpy()
    dino_boxes_xyxy = dino_boxes_numpy * np.array([w, h, w, h])

    print(f"Step 2: SAM generating masks for {len(dino_boxes)} objects...")
    masks, _, _ = sam_predictor.predict(
        point_coords=None,
        point_labels=None,
        box=dino_boxes_xyxy,
        multimask_output=False
    )
    return masks, image_cv



def visualize_results(image, masks):
    """
    Overlays the segmentation masks on the original image and prints results.
    """
    print("\n--- Generating Visualization ---")
    colors = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0]]

    if masks is not None and len(masks) > 0:
        overlay = np.zeros_like(image, dtype=np.uint8)
        for i, mask in enumerate(masks):
            color = colors[i % len(colors)]
            overlay[mask.squeeze()] = color

        alpha = 0.5
        final_image = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)
        print(f"Audit complete! Found and segmented {len(masks)} objects.")
    else:
        final_image = image
        print(" No objects found to display.")

    cv2_imshow(final_image)

if __name__ == "__main__":
    print("Zero-Shot Infrastructure Auditor v3.0")
    print("-----------------------------------")

    try:
        dino_model, sam_predictor = initialize_models()

        print("\n--- Please upload an image for the audit ---")
        uploaded = files.upload()
        image_filename = next(iter(uploaded))

        target_prompt = input("Enter your audit prompt (e.g., 'a solar panel array'): ")

        masks, image = zero_shot_segmentation(image_filename, target_prompt, dino_model, sam_predictor)
        visualize_results(image, masks)

    except Exception as e:
        print(f"\nAn error occurred: {e}")
        print("Please check the error message and try again.")